filter(!str_detect(word, "hölgyeim")) %>%
filter(!str_detect(word, "uraim")) %>%
filter(!str_detect(word, "képviselőtárs.*")) %>%
filter(!str_detect(word, "2015")) %>%
filter(!str_detect(word, "2010")) %>%
filter(!str_detect(word, "figyelmét")) %>%
filter(!str_detect(word, "Tisztelt")) %>%
filter(!str_detect(word, "magyar(.*)")) %>%
filter(!str_detect(word, "98")) %>%
filter(!str_detect(word, "2002")) %>%
filter(!str_detect(word, "2001")) %>%
filter(!str_detect(word, "képviselőtársam")) %>%
filter(!str_detect(word, "képviselő")) %>%
filter(!str_detect(word, "tisztelettel")) %>%
filter(!str_detect(word, "megtisztelő")) %>%
filter(!str_detect(word, "elnök")) %>%
filter(!str_detect(word, "emberek")) %>%
filter(!str_detect(word, "tudom")) %>%
filter(!str_detect(word, "ház")) %>%
filter(!str_detect(word, "képviselőtársam")) %>%
filter(!str_detect(word, "szeretném")) %>%
filter(!str_detect(word, "megtisztelő")) %>%
filter(!str_detect(word, "politikai")) %>%
filter(!str_detect(word, "ország")) %>%
filter(!str_detect(word, "tenni")) %>%
filter(!str_detect(word, "illeti")) %>%
filter(!str_detect(word, "mondani")) %>%
filter(!str_detect(word, "áll")) %>%
filter(!str_detect(word, "megtisztel.*")) %>%
filter(!str_detect(word, "figyelmüket")) %>%
filter(!str_detect(word, "bennünket")) %>%
filter(!str_detect(word, "tudjuk")) %>%
filter(!str_detect(word, "k[eé]pvisel.*")) %>%
filter(!str_detect(word, "var")) %>%
filter(!str_detect(word, "fontos")) %>%
filter(!str_detect(word, "dolog")) %>%
filter(!str_detect(word, "következő")) %>%
filter(!str_detect(word, "érdekében")) %>%
mutate(word = ifelse(word == "magyarországon", "magyarország", word))
words %>%
# filter(datum > "2014-05-01") %>%
count(word) %>%
with(wordcloud(word, n, max.words = 15))
positive_words <- read_csv("data/PrecoSenti/PrecoPos.txt", col_names = F) %>%
mutate(sentiment=1)
negative_words <- read_csv("data/PrecoSenti/PrecoNeg.txt", col_names = F) %>%
mutate(sentiment=-1)
hungarian_sentiment <- rbind(positive_words, negative_words) %>%
dplyr::rename(word = X1)
str(hungarian_sentiment)
word_sentiments <- words %>%
inner_join(hungarian_sentiment)
word_sentiments %>%
count(word, sentiment) %>%
mutate(word = reorder(word, n),
relsent = n * sentiment) %>%
arrange(-n) %>%
head(20) %>%
ggplot(aes(word, n * sentiment, fill = sentiment)) +
geom_col(show.legend = FALSE) +
labs(y = "Contribution to sentiment", x = NULL) +
coord_flip()
library(lubridate)
get.seasons <- function(dates, hemisphere = "N"){
library(data.table)
library(zoo)
library(dplyr)
years <- unique(year(dates))
years <- c(min(years - 1), max(years + 1), years) %>% sort
if(hemisphere == "N"){
seasons <- c("winter", "spring", "summer", "fall")}else{
seasons <- c("summer", "fall", "winter", "spring")}
dt.dates <- bind_rows(
data.table(date = as.Date(paste0(years, "-12-21")), init = seasons[1], type = "B"),# Summer in south hemisphere
data.table(date = as.Date(paste0(years, "-3-21")), init = seasons[2], type = "B"), # Fall in south hemisphere
data.table(date = as.Date(paste0(years, "-6-21")), init = seasons[3], type = "B"), # Winter in south hemisphere
data.table(date = as.Date(paste0(years, "-9-23")), init = seasons[4], type = "B"), # Winter in south hemisphere
data.table(date = dates, i = 1:(length(dates)), type = "A") # dates to compute
)[order(date)]
dt.dates[, init := zoo::na.locf(init)]
return(dt.dates[type == "A"][order(i)]$init)
}
word_sentiments %>%
group_by(ciklus, year = year(datum), season = get.seasons(datum, "N")) %>%
dplyr::summarize(score = sum(sentiment) / n()) %>%
ungroup() %>%
mutate(datum = paste0(year, "-", season)) %>%
select(-year) %>%
ggplot(aes(datum, score, fill = ciklus)) +
geom_col(show.legend = FALSE) +
coord_flip()
# facet_wrap(~method, ncol = 1, scales = "free_y")
word_sentiments %>%
group_by(ciklus) %>%
dplyr::summarize(score = sum(sentiment) / n()) %>%
ungroup() %>%
ggplot(aes(ciklus, score, fill = score)) +
geom_col(show.legend = FALSE)
# facet_wrap(~method, ncol = 1, scales = "free_y")
season("2014-12-01")
word_count <- words %>%
count(ciklus, word, sort = TRUE)
words_theme <- word_count %>%
bind_tf_idf(word, ciklus, n)
word_count <- word_count %>% filter(!str_detect(word, "képvisel(.*)")) %>%
filter(!str_detect(word, "tenni")) %>%
filter(!str_detect(word, "mondani")) %>%
filter(!str_detect(word, "gmo"))
words_theme <- word_count %>%
bind_tf_idf(word, ciklus, n) %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
arrange(ciklus, desc(tf_idf))
head(words_theme)
words_theme %>%
group_by(ciklus) %>%
top_n(15, tf_idf) %>%
ungroup() %>%
data.frame() %>%
mutate(word = reorder(word, -tf_idf)) %>%
ggplot(aes(word, tf_idf, fill = ciklus)) +
geom_col(show.legend = FALSE) +
facet_wrap(. ~ ciklus, ncol = 2, scales = "free") +
labs(x = NULL, y = "tf-idf") +
coord_flip()
words_theme %>%
group_by(ciklus) %>%
top_n(15, tf_idf) %>%
ungroup() %>%
data.frame() %>%
mutate(word = reorder(word, -tf_idf)) %>%
ggplot(aes(word, tf_idf, fill = ciklus)) +
geom_col(show.legend = FALSE) +
facet_wrap(. ~ ciklus, ncol = 2, scales = "free") +
labs(x = NULL, y = "tf-idf") +
coord_flip()
c_bigrams <- c %>%
unnest_tokens(bigram, word, token = "ngrams", n = 2)
library(tidyr)
bigrams_separated <- c_bigrams %>%
group_by(ciklus, datum) %>%
separate(bigram, c("word1", "word2"), sep = " ")
bigrams_filtered <- bigrams_separated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
bigrams_united <- bigrams_filtered %>%
unite(bigram, word1, word2, sep = " ")
bigram_counts <- bigrams_filtered %>%
count(word1, word2, sort = TRUE)
bigram_tf_idf <- bigrams_united %>%
count(ciklus, bigram) %>%
bind_tf_idf(bigram, ciklus, n) %>%
arrange(desc(tf_idf))
bigram_counts
bigrams_filtered %>%
filter(word2 == "street") %>%
count(book, word1, sort = TRUE)
bigram_tf_idf <- bigrams_united %>%
count(book, bigram) %>%
bind_tf_idf(bigram, book, n) %>%
arrange(desc(tf_idf))
bigram_tf_idf
bigram_tf_idf %>%
group_by(ciklus) %>%
top_n(10, tf_idf) %>%
dplyr::summarize(n())
## Bigram tf_idf
str(bigram_tf_idf)
bigram_tf_idf %>%
ungroup() %>% str
bigram_tf_idf %>%
ungroup() %>%
group_by(ciklus) %>%
top_n(10, tf_idf)
bigram_tf_idf %>%
ungroup() %>%
group_by(ciklus) %>%
top_n(10, tf_idf) %>%
dplyr::summarize(n())
bigram_tf_idf %>%
ungroup() %>%
group_by(ciklus) %>%
top_n(10, tf_idf) %>%
ungroup() %>%
data.frame() %>%
mutate(bigram = reorder(bigram, -tf_idf)) %>%
ggplot(aes(bigram, tf_idf, fill = ciklus)) +
geom_col(show.legend = FALSE) +
facet_wrap(. ~ ciklus, ncol = 3, scales = "free") +
labs(x = NULL, y = "tf-idf") +
coord_flip()
bigrams_separated <- c_bigrams %>%
group_by(ciklus, datum) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
ungroup()
bigrams_filtered <- bigrams_separated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
bigrams_united <- bigrams_filtered %>%
unite(bigram, word1, word2, sep = " ")
bigram_counts <- bigrams_filtered %>%
count(word1, word2, sort = TRUE)
bigram_tf_idf <- bigrams_united %>%
count(ciklus, bigram) %>%
bind_tf_idf(bigram, ciklus, n) %>%
arrange(desc(tf_idf))
## Bigram tf_idf
str(bigram_tf_idf)
bigram_tf_idf %>%
ungroup() %>%
group_by(ciklus) %>%
top_n(10, tf_idf) %>%
ungroup() %>%
data.frame() %>%
mutate(bigram = reorder(bigram, -tf_idf)) %>%
ggplot(aes(bigram, tf_idf, fill = ciklus)) +
geom_col(show.legend = FALSE) +
facet_wrap(. ~ ciklus, ncol = 3, scales = "free") +
labs(x = NULL, y = "tf-idf") +
coord_flip()
library(ggraph)
library(igraph)
bigram_counts
bigram_graph <- bigram_counts %>%
select(from=word1, to=word2)
filter(n > 20) %>%
graph_from_data_frame()
bigram_graph
set.seed(2016)
a <- grid::arrow(type = "closed", length = unit(.15, "inches"))
bigram_graph <- data.frame(ungroup(bigram_graph))
head(bigram_graph)
manual_layout <- create_layout(graph = igraph_data,
layout = "manual", node.positions = data2)
ggraph(bigram_graph, layout = "fr") +
geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
arrow = a, end_cap = circle(.07, 'inches')) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
theme_void()
bigram_graph <- bigram_counts %>%
filter(n > 20) %>%
graph_from_data_frame()
a <- grid::arrow(type = "closed", length = unit(.15, "inches"))
manual_layout <- create_layout(graph = igraph_data,
layout = "manual", node.positions = data2)
ggraph(bigram_graph, layout = "fr") +
geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
arrow = a, end_cap = circle(.07, 'inches')) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
theme_void()
stri_enc_toascii(hu_stop_word$word)
head(hu_stop_word)
iconv(hu_stop_word$word, from="ASCII", to="UTF-8//TRANSLIT")
iconv(hu_stop_word$word, from="ASCII", to="UTF-8")
hu_stop_word <- read.csv(paste0(getwd(), "/data/stopwords-hu.txt"),
encoding = "UTF-8") %>%
dplyr::rename(word = a)
head(hu_stop_word)
hu_stop_word <- read.csv(paste0(getwd(), "/data/stopwords-hu.txt"),
fileEncoding = "UTF-8") %>%
dplyr::rename(word = a)
head(hu_stop_word)
hu_stop_word <- read.csv(paste0(getwd(), "/data/stopwords-hu.txt"),
encoding = "UTF-8") %>%
dplyr::rename(word = a)
head(hu_stop_word)
hu_stop_word
stri_enc_mark(hu_stop_word$word)
addr <- "http://comunicacion.senado.gob.mx/index.php/informacion/versiones/14694-version-estenografica-de-la-sesion-de-la-comision-permanente-celebrada-el-13-de-agosto-de-2014.html"
read.html.con <- file(description = addr, encoding = "UTF-8", open = "rt")
read.html.con
# Read in cycles of 1000 characters
html.text <- c()
i = 0
while(length(html.text) == i) {
html.text <- append(html.text, readChar(con = read.html.con,nchars = 1000))
cat(i <- i + 1)
}
# close reading connection
close(read.html.con)
# Paste everything back together & at the same time, convert from UTF-8
# to... UTF-8 with iconv(). I know. It's crazy. Encodings are secretely
# meant to drive us insane.
content <- paste0(iconv(html.text, from="UTF-8", to = "UTF-8"), collapse="")
# Paste everything back together & at the same time, convert from UTF-8
# to... UTF-8 with iconv(). I know. It's crazy. Encodings are secretely
# meant to drive us insane.
content <- paste0(iconv(html.text, from="UTF-8", to = "UTF-8"), collapse="")
content
hu_stop_word <- read.csv(paste0(getwd(), "/data/stopwords-hu.txt"),
fileEncoding = "UTF-8-BOM") %>%
dplyr::rename(word = a)
hu_stop_word
View(hu_stop_word)
stri_enc_mark(hu_stop_word$word)
hu_stop_word <- read.csv(paste0(getwd(), "/data/stopwords-hu.txt"),
fileEncoding = "UTF-8-BOM") %>%
dplyr::rename(word = a)
hu_stop_word <- read.csv(paste0(getwd(), "/data/stopwords-hu.txt")) %>%
dplyr::rename(word = a)
stri_enc_mark(hu_stop_word$word)
stri_enc_mark(hu_stop_word$word)
hu_stop_word <- read.csv(paste0(getwd(), "/data/stopwords-hu.txt")) %>%
dplyr::rename(word = a)
hu_stop_word %>% filter(stri_enc_mark(word) == "native")
hu_stop_word %>% filter(stri_enc_mark(word) == "ASCII")
a <- hu_stop_word %>% filter(stri_enc_mark(word) == "ASCII")
View(a)
a <- hu_stop_word %>% filter(stri_enc_mark(word) == "native")
View(a)
stri_enc_mark(hu_stop_word$word)
stri_enc_mark(a$word)
stri_enc_mark(hu_stop_word$word)
unique(stri_enc_mark(hu_stop_word$word))
head(hu_stop_word)
iconv(hu_stop_word$word, from="ASCII", to="UTF-8")
stri_enc_toascii(hu_stop_word$word)
library(tidytext)
words <- c %>%
unnest_tokens(word, word) %>%
anti_join(hu_stop_word) %>%
filter(!str_detect(word, "^a$")) %>%
filter(!str_detect(word, "egyébként")) %>%
filter(!str_detect(word, "tisztelt")) %>%
filter(!str_detect(word, "hölgyeim")) %>%
filter(!str_detect(word, "uraim")) %>%
filter(!str_detect(word, "képviselőtárs.*")) %>%
filter(!str_detect(word, "2015")) %>%
filter(!str_detect(word, "2010")) %>%
filter(!str_detect(word, "figyelmét")) %>%
filter(!str_detect(word, "Tisztelt")) %>%
filter(!str_detect(word, "magyar(.*)")) %>%
filter(!str_detect(word, "98")) %>%
filter(!str_detect(word, "2002")) %>%
filter(!str_detect(word, "2001")) %>%
filter(!str_detect(word, "képviselőtársam")) %>%
filter(!str_detect(word, "képviselő")) %>%
filter(!str_detect(word, "tisztelettel")) %>%
filter(!str_detect(word, "megtisztelő")) %>%
filter(!str_detect(word, "elnök")) %>%
filter(!str_detect(word, "emberek")) %>%
filter(!str_detect(word, "tudom")) %>%
filter(!str_detect(word, "ház")) %>%
filter(!str_detect(word, "képviselőtársam")) %>%
filter(!str_detect(word, "szeretném")) %>%
filter(!str_detect(word, "megtisztelő")) %>%
filter(!str_detect(word, "politikai")) %>%
filter(!str_detect(word, "ország")) %>%
filter(!str_detect(word, "tenni")) %>%
filter(!str_detect(word, "illeti")) %>%
filter(!str_detect(word, "mondani")) %>%
filter(!str_detect(word, "áll")) %>%
filter(!str_detect(word, "megtisztel.*")) %>%
filter(!str_detect(word, "figyelmüket")) %>%
filter(!str_detect(word, "bennünket")) %>%
filter(!str_detect(word, "tudjuk")) %>%
filter(!str_detect(word, "k[eé]pvisel.*")) %>%
filter(!str_detect(word, "var")) %>%
filter(!str_detect(word, "fontos")) %>%
filter(!str_detect(word, "dolog")) %>%
filter(!str_detect(word, "következő")) %>%
filter(!str_detect(word, "érdekében")) %>%
mutate(word = ifelse(word == "magyarországon", "magyarország", word))
words %>% filter(word == "hogy")
words %>% filter(word == "az")
words %>%
# filter(datum > "2014-05-01") %>%
count(word) %>%
with(wordcloud(word, n, max.words = 15))
library(wordcloud)
words %>%
count(word) %>%
with(wordcloud(word, n, max.words = 15))
words %>% filter(word == "és")
words <- c %>%
unnest_tokens(word, word) %>%
anti_join(hu_stop_word) %>%
filter(!str_detect(word, "^a$")) %>%
filter(!str_detect(word, "egyébként")) %>%
filter(!str_detect(word, "tisztelt")) %>%
filter(!str_detect(word, "hölgyeim")) %>%
filter(!str_detect(word, "uraim")) %>%
filter(!str_detect(word, "képviselőtárs.*")) %>%
filter(!str_detect(word, "2015")) %>%
filter(!str_detect(word, "2010")) %>%
filter(!str_detect(word, "figyelmét")) %>%
filter(!str_detect(word, "Tisztelt")) %>%
filter(!str_detect(word, "magyar(.*)")) %>%
filter(!str_detect(word, "98")) %>%
filter(!str_detect(word, "2002")) %>%
filter(!str_detect(word, "2001")) %>%
filter(!str_detect(word, "képviselőtársam")) %>%
filter(!str_detect(word, "képviselő")) %>%
filter(!str_detect(word, "tisztelettel")) %>%
filter(!str_detect(word, "megtisztelő")) %>%
filter(!str_detect(word, "elnök")) %>%
filter(!str_detect(word, "emberek")) %>%
filter(!str_detect(word, "tudom")) %>%
filter(!str_detect(word, "ház")) %>%
filter(!str_detect(word, "képviselőtársam")) %>%
filter(!str_detect(word, "szeretném")) %>%
filter(!str_detect(word, "megtisztelő")) %>%
filter(!str_detect(word, "politikai")) %>%
filter(!str_detect(word, "ország")) %>%
filter(!str_detect(word, "tenni")) %>%
filter(!str_detect(word, "illeti")) %>%
filter(!str_detect(word, "mondani")) %>%
filter(!str_detect(word, "áll")) %>%
filter(!str_detect(word, "megtisztel.*")) %>%
filter(!str_detect(word, "figyelmüket")) %>%
filter(!str_detect(word, "bennünket")) %>%
filter(!str_detect(word, "tudjuk")) %>%
filter(!str_detect(word, "k[eé]pvisel.*")) %>%
filter(!str_detect(word, "var")) %>%
filter(!str_detect(word, "fontos")) %>%
filter(!str_detect(word, "dolog")) %>%
filter(!str_detect(word, "következő")) %>%
filter(!str_detect(word, "érdekében")) %>%
filter(!str_detect(word, "és")) %>%
mutate(word = ifelse(word == "magyarországon", "magyarország", word))
words %>% filter(word == "és")
View(hu_stop_word)
a <- hu_stop_word %>% filter(stri_enc_mark(word) == "native")
library(utf8)
enc2native(a$word)
a$word
enc2native(as.character(a$word))
enc2utf8(as.character(a$word))
hu_stop_word <- read.csv(paste0(getwd(), "/data/stopwords-hu.txt"),
encoding = "native") %>%
dplyr::rename(word = a)
a <- hu_stop_word %>% filter(stri_enc_mark(word) == "native")
enc2utf8(as.character(a$word))
head(hu_stop_word)
tail(hu_stop_word)
hu_stop_word <- read.csv(paste0(getwd(), "/data/stopwords-hu.txt"),
encoding = "UTF-8") %>%
dplyr::rename(word = a)
tail(hu_stop_word)
hu_stop_word
a <- hu_stop_word %>% filter(stri_enc_mark(word) == "native")
a
a <- hu_stop_word %>% filter(stri_enc_mark(word) == "native")
stri_enc_mark(hu_stop_word$word)
a <- hu_stop_word %>% filter(stri_enc_mark(word) == "UTF-8")
a
hu_stop_word <- read.csv(paste0(getwd(), "/data/stopwords-hu.txt"),
encoding = "UTF-8") %>%
dplyr::rename(word = a)
library(tidytext)
words <- c %>%
unnest_tokens(word, word) %>%
anti_join(hu_stop_word) %>%
filter(!str_detect(word, "^a$")) %>%
filter(!str_detect(word, "egyébként")) %>%
filter(!str_detect(word, "tisztelt")) %>%
filter(!str_detect(word, "hölgyeim")) %>%
filter(!str_detect(word, "uraim")) %>%
filter(!str_detect(word, "képviselőtárs.*")) %>%
filter(!str_detect(word, "2015")) %>%
filter(!str_detect(word, "2010")) %>%
filter(!str_detect(word, "figyelmét")) %>%
filter(!str_detect(word, "Tisztelt")) %>%
filter(!str_detect(word, "magyar(.*)")) %>%
filter(!str_detect(word, "98")) %>%
filter(!str_detect(word, "2002")) %>%
filter(!str_detect(word, "2001")) %>%
filter(!str_detect(word, "képviselőtársam")) %>%
filter(!str_detect(word, "képviselő")) %>%
filter(!str_detect(word, "tisztelettel")) %>%
filter(!str_detect(word, "megtisztelő")) %>%
filter(!str_detect(word, "elnök")) %>%
filter(!str_detect(word, "emberek")) %>%
filter(!str_detect(word, "tudom")) %>%
filter(!str_detect(word, "ház")) %>%
filter(!str_detect(word, "képviselőtársam")) %>%
filter(!str_detect(word, "szeretném")) %>%
filter(!str_detect(word, "megtisztelő")) %>%
filter(!str_detect(word, "politikai")) %>%
filter(!str_detect(word, "ország")) %>%
filter(!str_detect(word, "tenni")) %>%
filter(!str_detect(word, "illeti")) %>%
filter(!str_detect(word, "mondani")) %>%
filter(!str_detect(word, "áll")) %>%
filter(!str_detect(word, "megtisztel.*")) %>%
filter(!str_detect(word, "figyelmüket")) %>%
filter(!str_detect(word, "bennünket")) %>%
filter(!str_detect(word, "tudjuk")) %>%
filter(!str_detect(word, "k[eé]pvisel.*")) %>%
filter(!str_detect(word, "var")) %>%
filter(!str_detect(word, "fontos")) %>%
filter(!str_detect(word, "dolog")) %>%
filter(!str_detect(word, "következő")) %>%
filter(!str_detect(word, "érdekében")) %>%
filter(!str_detect(word, "és")) %>%
mutate(word = ifelse(word == "magyarországon", "magyarország", word))
words %>% filter(word == "és")
library(wordcloud)
words %>%
count(word) %>%
with(wordcloud(word, n, max.words = 15))
positive_words <- read_csv("data/PrecoSenti/PrecoPos.txt", col_names = F) %>%
mutate(sentiment=1)
positive_words
View(positive_words)
View(c)
c %>% tail(-1)
d <- c %>% head(-1)
View(d)
c <- c %>% tail(-1)
library(tidytext)
